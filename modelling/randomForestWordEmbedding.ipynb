{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/barnabasepres/University/TDK/trump_speech_analysis/word2vec_vectors.csv\")\n",
    "df['Vector2'] = df['Vector'].apply(ast.literal_eval)\n",
    "def getVectorList(vector):\n",
    "    vector_list = list()\n",
    "    for i in vector[0]:\n",
    "        vector_list.append(i)\n",
    "\n",
    "    return vector_list\n",
    "\n",
    "df['Vector3'] = df['Vector2'].apply(getVectorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data for modelling with vectors\n",
    "df_for_model = pd.read_excel(\"data_for_rfmodel.xlsx\")\n",
    "df_for_model.drop(columns=[\"tfidf1\", \"tfidf2\", \"tfidf3\", \"tfidf4\", \"tfidf5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['textid2'] = 'text' + df['textid'].astype(str)\n",
    "df.head(1)\n",
    "\n",
    "num_vectors = 5\n",
    "num_rows = df.shape[0] // num_vectors  # Ensure it is divisible\n",
    "\n",
    "# Create an empty DataFrame with proper structure\n",
    "vector_form_models = pd.DataFrame(columns=[f'Vector{i+1}' for i in range(num_vectors)])\n",
    "\n",
    "# Reshape df column 8 into 5 columns\n",
    "vector_for_models = pd.DataFrame(df.iloc[:num_rows * num_vectors, 8].values.reshape(num_rows, num_vectors),\n",
    "                            columns=[f'Vector{i+1}' for i in range(num_vectors)])\n",
    "\n",
    "vector_for_models.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_for_models['doc_id'] = np.arange(1, 74) \n",
    "vector_for_models['doc_id'] = 'text' + vector_for_models['doc_id'].astype(str)\n",
    "\n",
    "df_for_model_final = pd.merge(df_for_model, vector_for_models, on='doc_id')\n",
    "\n",
    "\n",
    "df_for_model_final['Vector1_mean'] = df_for_model_final['Vector1'].apply(np.mean)\n",
    "df_for_model_final['Vector2_mean'] = df_for_model_final['Vector2'].apply(np.mean)\n",
    "df_for_model_final['Vector3_mean'] = df_for_model_final['Vector3'].apply(np.mean)\n",
    "df_for_model_final['Vector4_mean'] = df_for_model_final['Vector4'].apply(np.mean)\n",
    "df_for_model_final['Vector5_mean'] = df_for_model_final['Vector5'].apply(np.mean)\n",
    "df_for_model_final.head(2)\n",
    "\n",
    "df_for_model_final.to_csv(\"df_for_model_final_hpfilter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get packeges for random forest models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import shap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for predicting sentiment score\n",
    "#data preprocessing for random forest regression\n",
    "encoder = LabelEncoder()\n",
    "df_for_model_final['state'] = encoder.fit_transform(df_for_model_final['state'])\n",
    "\n",
    "y = \"positive\"\n",
    "y_data = df_for_model_final[y]\n",
    "X_data = df_for_model_final[[\"day\", \"day_of_the_week\", \"state\", \"nth_speech_in_state\", \"CTTR\", \n",
    "                             \"scale\", \"popularity\", \"frequency\", \"Vector1_mean\", \"Vector2_mean\", \"Vector3_mean\", \n",
    "                             \"Vector4_mean\", \"Vector5_mean\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=2024)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=2024, max_depth=5, min_samples_leaf=6)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "#predicting \n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_on_train = rf_model.predict(X_train)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse2 = mean_squared_error(y_train, y_pred_on_train)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2_train = r2_score(y_train, y_pred_on_train)\n",
    "print(mse, mse2, r2, r2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "plt.plot(y_pred_on_train, label='Predicted positive sentiment score')\n",
    "plt.plot(y_train, label='Actual positive sentiment score')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X10 = shap.utils.sample(X_train, 10)\n",
    "explainer = shap.Explainer(rf_model.predict, X10)\n",
    "\n",
    "shap_values = explainer(X_train)\n",
    "shap.plots.waterfall(shap_values[1], max_display=14)\n",
    "\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text_auto_precision = 4\n",
    "X10 = shap.utils.sample(X_train, 10)\n",
    "explainer = shap.Explainer(rf_model.predict, X10)\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# Set precision (e.g., 4 digits after decimal)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "# Sample explainer and compute SHAP values\n",
    "X10 = shap.utils.sample(X_train, 10, random_state=42)\n",
    "explainer = shap.Explainer(rf_model.predict, X10)\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# Waterfall plot (with high precision display in hover text)\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.plots.waterfall(shap_values[1], max_display=14, show=False)\n",
    "plt.title(\"SHAP Waterfall Plot with High-Precision Values\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 🐝 Beeswarm plot for feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "shap.plots.beeswarm(shap_values, max_display=14, show=False)\n",
    "plt.title(\"SHAP Beeswarm Plot — Feature Importance Overview\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf_model.predict(X_train.head(1))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official SHAP colors\n",
    "shap_blue = \"#008bfb\" # #0080FF\n",
    "shap_red = \"#ff0051\" \n",
    "# Choose a specific instance\n",
    "shap_val = shap_values[0]\n",
    "base_value = shap_val.base_values\n",
    "contribs = shap_val.values\n",
    "feature_names = shap_val.feature_names\n",
    "feature_vals = shap_val.data\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'SHAP': contribs,\n",
    "    'Value': feature_vals\n",
    "})\n",
    "\n",
    "# Sort by absolute SHAP value\n",
    "df = df.reindex(df['SHAP'].abs().sort_values(ascending=False).index)\n",
    "df = df.head(14).reset_index(drop=True)\n",
    "\n",
    "# Assign colors based on SHAP value sign (positive=blue, negative=red)\n",
    "colors = [shap_blue if val > 0 else shap_red for val in df['SHAP']]\n",
    "\n",
    "# Calculate left edge for bars\n",
    "cumulative = base_value + df['SHAP'].cumsum() - df['SHAP']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, row in df.iterrows():\n",
    "    plt.barh(i, row['SHAP'], left=cumulative[i], color=colors[i])\n",
    "    label = f\"{row['SHAP']:.4f}\"\n",
    "    plt.text(cumulative[i] + row['SHAP'] / 2, i, label,\n",
    "             va='center', ha='center', fontsize=9, color='black')\n",
    "\n",
    "# Y-axis labels\n",
    "plt.yticks(\n",
    "    ticks=range(len(df)),\n",
    "    labels=[f\"{f} = {v:.4f}\" for f, v in zip(df['Feature'], df['Value'])]\n",
    ")\n",
    "\n",
    "plt.title(\"Individual feature importance\", fontsize=14)\n",
    "plt.xlabel(\"Prediction Contribution\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"SHAP values explain this instance:\")\n",
    "print(pd.Series(feature_vals, index=feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for predicting popularity\n",
    "y = \"popularity_tminus1\"\n",
    "y_data = df_for_model_final[y]\n",
    "X_data = df_for_model_final[[\"day\", \"state\", \"nth_speech_in_state\", \"CTTR\", \n",
    "                             \"scale\", \"positive\", \"frequency\", \"Vector1_mean\", \"Vector2_mean\", \"Vector3_mean\", \n",
    "                             \"Vector4_mean\", \"Vector5_mean\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=2024)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=2024, max_depth=5, min_samples_leaf=6)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "#predicting \n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_on_train = rf_model.predict(X_train)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse2 = mean_squared_error(y_train, y_pred_on_train)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2_for_train = r2_score(y_train, y_pred_on_train)\n",
    "print(mse, mse2, r2, r2_for_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X10 = shap.utils.sample(X_test, 10)\n",
    "explainer = shap.Explainer(rf_model.predict, X10)\n",
    "\n",
    "shap_values = explainer(X_test)\n",
    "shap.plots.waterfall(shap_values[2], max_display=14)\n",
    "\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model for predicting CTTR\n",
    "y = \"CTTR\"\n",
    "y_data = df_for_model_final[y]\n",
    "X_data = df_for_model_final[[\"day\", \"day_of_the_week\", \"state\", \"nth_speech_in_state\", \"scale\", \n",
    "                             \"popularity\", \"positive\", \"frequency\", \"Vector1_mean\", \"Vector2_mean\", \"Vector3_mean\", \n",
    "                             \"Vector4_mean\", \"Vector5_mean\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=2024)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=2024)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "#predicting \n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(mse, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text_auto_precision = 4\n",
    "X10 = shap.utils.sample(X_train, 10)\n",
    "explainer = shap.Explainer(rf_model.predict, X10)\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# Set precision (e.g., 4 digits after decimal)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "# Sample explainer and compute SHAP values\n",
    "X10 = shap.utils.sample(X_train, 10, random_state=42)\n",
    "explainer = shap.Explainer(rf_model.predict, X10)\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# Waterfall plot (with high precision display in hover text)\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.plots.waterfall(shap_values[1], max_display=14, show=False)\n",
    "plt.title(\"SHAP Waterfall Plot with High-Precision Values\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 🐝 Beeswarm plot for feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "shap.plots.beeswarm(shap_values, max_display=14, show=False)\n",
    "plt.title(\"SHAP Beeswarm Plot — Feature Importance Overview\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

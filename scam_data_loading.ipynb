{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "from pyannote.audio import Pipeline\n",
    "from pydub import AudioSegment\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import torch\n",
    "import os\n",
    "import whisper\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import accelerate\n",
    "import pprint \n",
    "pd.set_option('display.max_rows', 500)\n",
    "warnings.filterwarnings('ignore')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get video urls\n",
    "speeches = pd.read_excel(\"speeches.xlsx\")\n",
    "#helo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script to save audio files\n",
    "def save_audio(url, output_path, filename):\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        print(f\"Downloading: {yt.title}\")\n",
    "        \n",
    "        # Get audio-only stream\n",
    "        ys = yt.streams.get_audio_only()\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        \n",
    "        # Temporary file name (original format)\n",
    "        temp_filename = f\"{filename}.webm\"\n",
    "        temp_filepath = os.path.join(output_path, temp_filename)\n",
    "        \n",
    "        # Download audio in original format\n",
    "        ys.download(output_path=output_path, filename=temp_filename)\n",
    "        \n",
    "        # Convert to MP3\n",
    "        final_filename = f\"{filename}.mp3\"\n",
    "        final_filepath = os.path.join(output_path, final_filename)\n",
    "        audio = AudioSegment.from_file(temp_filepath)\n",
    "        audio.export(final_filepath, format=\"mp3\")\n",
    "        \n",
    "        # Remove the temporary file\n",
    "        os.remove(temp_filepath)\n",
    "        print(f\"Downloaded and converted to MP3: {final_filename}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"----- Download failed: -----\")\n",
    "        print(f\"URL: {url}\")\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = speeches[\"url\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, url in enumerate(url_list, start=1):\n",
    "    output_path = \"./audio_files\"  \n",
    "    filename = f\"speech_{i}_{speeches[\"date\"][i-1]}_{speeches[\"state\"][i-1]}\"\n",
    "    save_audio(url, output_path=output_path, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate model to script the audio files\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=False, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"Model and pipe has been initiated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(url_list)):\n",
    "    if speeches[\"trimming_needed\"][i] == \"Yes\":\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Generating transcript of speech_{i+1}_{speeches[\"date\"][i]}_{speeches[\"state\"][i]}.mp3\")\n",
    "\n",
    "        result_txt = pipe(f\"./audio_files/speech_{i+1}_{speeches[\"date\"][i]}_{speeches[\"state\"][i]}.mp3\", return_timestamps=True)\n",
    "        text_to_add = list(result_txt.values())[0]\n",
    "\n",
    "        print(\"Transcript has been generated.\")\n",
    "        os.makedirs(\"text_files\", exist_ok=True)\n",
    "        file_path = os.path.join(\"text_files\", f\"speech_{i+1}_{speeches[\"date\"][i]}_{speeches[\"state\"][i]}.txt\")\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(text_to_add)\n",
    "\n",
    "        print(\"Transcript has been added to the folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
